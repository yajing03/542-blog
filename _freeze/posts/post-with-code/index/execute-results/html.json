{
  "hash": "bd98df8acab24abec3d2e7f9c07c37e8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"How Data Science Empowers Smarter Home Buying: Insights from Strathcona county data\"\nauthor: \"Yajing Liu\"\ndate: \"2025-01-14\"\ncategories: ['explanations']\noutput: html_document\n---\n\n\n\n\n### Introduction\n\nBuying a house is a significant financial purchase in one's life time. However, it is not easy to access a real estate's true value in today's market. This is when Data Science can help - by using Data Analytic skills and predictive modelling, we can help home buyers access the true value of the house they are looking for and provide them guidance on whether the house to price is a reasonable purchase.\n\nIn this blog, we explore how Ridge Regression, a robust data science method, can be used to predict house prices. Using the 2023 Property Tax Assessment dataset from Strathcona County, we demonstrate how features like property size and the presence of amenities influence pricing. By the end, you’ll understand how data science can guide smarter home-buying decisions.\n\n### Understanding the Data\n\nOur analysis is based on the 2023 Property Tax Assessment dataset, which includes key features influencing house prices:\n\nProperty Size (meters): The size of the house in square meters.\n\nGarage (garage): Whether the house has a garage (Y/N).\n\nFireplace (firepl): Whether the house has a fireplace (Y/N).\n\nBasement (bsmt): Whether the house has a basement (Y/N).\n\nBuilding Evaluation (bdevl): Whether the building has been officially evaluated (Y/N).\n\nWe began by validating the data, ensuring there were no missing values, duplicates, or anomalies. Visualizations, such as scatter plots and correlation matrices, revealed key relationships, like the strong positive correlation between property size and house prices. Larger homes with amenities like garages and basements consistently showed higher valuations.\n\n### Modeling Approach\n\nWhy Ridge Regression?\n\nRidge Regression is a type of linear regression that addresses multicollinearity—a situation where predictor variables are highly correlated. By adding a regularization term, Ridge Regression prevents overfitting, ensuring the model generalizes well to new data. This makes it an excellent choice for predicting house prices where features like size and amenities may be interrelated.\n\n### Data Preparation\n\nTo prepare the data for modeling:\n\nCategorical Features: One-hot encoding was applied to variables like garage, firepl, bsmt, and bdevl to make them suitable for the Ridge model.\n\nNumeric Features: Standard scaling was used to normalize property sizes.\n\nSplitting the Data: The dataset was divided into training (70%) and testing (30%) sets.\n\nModel Training and Validation\n\nUsing Scikit-learn, we created a pipeline combining feature transformation and Ridge Regression. The model was trained and validated using 5-fold cross-validation, achieving a training score of 0.575 and a test score of 0.564. While these scores indicate a good fit, some variability in the test score suggests room for improvement through hyperparameter tuning.\n\n### Results and Insights\n\nPredicted Prices\n\nThe model was tested on new data, including features for 10 houses. Below are sample predictions:\n\n#### Sample data for illustration\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(knitr)\n# Sample data for illustration\nkable(\n  data.frame(\n    Property_Size_m2 = c(174.23, 132.76, 68.54),\n    Garage = c(\"Y\", \"Y\", \"N\"),\n    Fireplace = c(\"Y\", \"N\", \"N\"),\n    Basement = c(\"Y\", \"Y\", \"N\"),\n    Building_Evaluation = c(\"N\", \"Y\", \"N\"),\n    Predicted_Price = c(537035, 457895, 212530)\n  ),\n  caption = \"Sample predictions of house prices.\"\n)\n```\n\n::: {.cell-output-display}\n\n\nTable: Sample predictions of house prices.\n\n| Property_Size_m2|Garage |Fireplace |Basement |Building_Evaluation | Predicted_Price|\n|----------------:|:------|:---------|:--------|:-------------------|---------------:|\n|           174.23|Y      |Y         |Y        |N                   |          537035|\n|           132.76|Y      |N         |Y        |Y                   |          457895|\n|            68.54|N      |N         |N        |N                   |          212530|\n\n\n:::\n:::\n\n\n\n\n### Key Takeaways\n\nProperty Size Matters: Larger properties are consistently valued higher.\n\nAmenities Add Value: Features like garages and fireplaces positively influence house prices.\n\nModel Limitations: Ridge Regression’s linear nature may not fully capture complex interactions, underscoring the need for future enhancements.\n\n### Limitations and Future Directions\n\nWhile the Ridge model provides valuable insights, there are limitations:\n\nLinear Assumptions: The model assumes a linear relationship between features and prices, which might oversimplify real-world dynamics.\n\nFeature Scope: Additional factors like the number of bedrooms, bathrooms, and proximity to amenities were not included but could enhance predictions.\n\nData Bias: Regional trends and external economic factors were not accounted for.\n\nFuture work could explore non-linear models like decision trees or include spatial and temporal data to better capture market trends.\n\n### Conclusion\n\nPredictive modeling can be a powerful ally for first-time homebuyers. By using Ridge Regression, we’ve demonstrated how publicly available data can estimate house prices, offering transparency and confidence to buyers. As data science tools evolve, so does the ability to make smarter, data-driven decisions in real estate.\n\nIf you’re considering buying a house, why not explore how data science can guide your journey? Start by analyzing property features, and let the data reveal the true value of your future home!",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}